{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267fa872-4102-44f4-b3f3-9cfdf97ac798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## RAG implemetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b475e6-68e3-4075-8f99-92e71fe245d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"asia-southeast1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafe0c4d-659f-43ad-900c-c74bbbb69970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jupyter/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "# from langchain_vertexai import ChatGemini\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import uuid, os\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatVertexAI(\n",
    "    # model_name=\"gemini-pro\", # Replace with your desired Gemini model\n",
    "    # model = GenerativeModel(\"gemini-pro\")\n",
    "    # model = GenerativeModel(\"gemini-1.5-pro-preview-0215\")\n",
    "    model = \"gemini-1.5-pro-002\",\n",
    "    project_id=os.getenv(PROJECT_ID), # Your Vertex AI project ID\n",
    "    location=\"us-central1\", # Your Vertex AI location\n",
    ")\n",
    "\n",
    "\n",
    "def generate_pro(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    full_prompt = '''summarize the prompt below and do note prompt below will be send to imagen mode so please clean up any sensitve words and replace them into unblocked words like replace girl or lady can be replaced by female human and so on : ''' + input_prompt\n",
    "    responses = model.generate_content(\n",
    "    input_prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 8190,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1\n",
    "    },stream=False,)\n",
    "    \n",
    "    # print (responses.text)\n",
    "    \n",
    "    return(responses.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7795438-82c1-412e-9607-ef18d33c29a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/conda/envs/pytorch/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain-community langchain-core\n",
    "%pip install faiss-cpu\n",
    "%pip install -qU duckduckgo-search langchain-community\n",
    "\n",
    "\n",
    "### RESTART KERNEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79ca5cc-4d7b-4713-86b2-770080763579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q pypdf\n",
    "# !pip install -q faiss-gpu\n",
    "# !pip install faiss-cpu\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/GCP-Machine-learning-Certification.pdf\")\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37de4dea-2db6-47ca-9c12-b544ee7cbdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/GCP-Machine-learning-Certification.pdf', 'page': 0}, page_content='\\ue914Topic Cheatsheet for GCP‚Äôs Professional Machine Learning Engineer Beta Exam\\nAuthors/contributors: David Chen, PhD\\nCredits & disclaimers can be found in READMEsection of the source repository. Some references are included as %comments orhyperlinks the source file.\\nAbbreviations\\nCommon abbreviations . ML, machine learning; DL, deep learn-\\ning; AI, artificial intelligence, CV, computer vision; GC(P), Google\\nCloud (Platform); CI/CD: continuous integration / continuous de-\\nlivery; SDK, software development kit; API, application program-\\nming interface; K8s, Kubernetes; GKE, Google Kubernetes Engine.\\nMLE, maximum likelihood estimation; ROC, receiver-operation\\ncurve; AU(RO)C, area under the (receiver-operation) curve\\nI. Preparation for ML\\nUnderstanding the ‚ÄùData Science Steps for ML‚Äù\\n1.Data extraction\\n2.Exploratory data analysis\\n3.Data preparation for the ML Task\\n4.Model training\\n5.Model evaluation\\n6.Model validation\\n7.Model serving\\n‚Ä¢Microservices with REST API\\n‚Ä¢Deployment on mobile devices\\n‚Ä¢Batch predictions\\n8.Model monitoring\\nDeÔ¨Åning an ML Problem\\nML as Solution to Business Problems\\n‚Ä¢(Re)define your business problems\\n‚Ä¢Consider whether the problem could be solved without ML\\n‚Ä¢Define/anticipate utility of the ML output\\n‚Ä¢Identify data sources\\n‚Ä¢Pre-define ‚Äùsuccess‚Äù to solving the business challenge\\n‚ÄìMetric(s) used to define success\\n‚ÄìKey results (product or deliverables)\\n‚ÄìIncorrect or low-quality output (i.e. ‚Äùunsuccessful‚Äù\\nmodels)\\nComponents of an ML Solution\\n‚Ä¢Define Predictive Outcome\\n‚Ä¢IdentifyProblemType: Supervised(ClassificationorRegres-\\nsion), Unsupervised, Reinforcement\\n‚Ä¢Identify Input Feature Format\\n‚Ä¢Feasibility and implementation\\nData Preparation\\nData Ingestion\\n‚Ä¢Obtaining & importing data for use or storage\\n‚Ä¢File input types\\n‚Ä¢Database maintenance, migration\\n‚Ä¢Streaming data (from IoT devices, databases, or enduser)Exploratory Data Analysis (EDA)\\n‚Ä¢Evaluation of data quality (domain- and organization-\\nspecific knowledge/information may be needed)\\n‚Ä¢Data visualization (descriptive statistics)\\n‚Ä¢Inferential statistics (e.g. t-test to compare means, KS-tests\\nto compare distributions) as needed, scale as needed\\nFeature Engineering\\n‚Ä¢Necessary (e.g. time series) or beneficial in many ML tasks:\\n‚Ä¢Encoding structured data types\\n‚Ä¢Feature Crosses : used to define a synthetic feature when data\\ncannot be linearly separated (e.g. feature cross products\\nx1√óx2\\n‚Ä¢Feature selection , e.g.\\n‚ÄìUnivariate statistical methods (e.g. ùúí2test, t-\\ntest/linear model)\\n‚ÄìRecursive Feature Elimination (RFE)\\nSpecial considerations\\n‚Ä¢Imbalanced class distributions\\n‚ÄìNeeds to be known, at minimum\\n‚ÄìAffects the metrics to employ (e.g. F1 score, AUC\\nwould be superior to crude accuracy in imbalanced bi-\\nnary classification)\\n‚ÄìCan affect optimization choices: modify objective\\nfunction; oversampling the minority class(es)\\n‚Ä¢Data Leakage\\n‚ÄìCertain features available in your training data might\\nnot be available in the unknowns to predict!\\n‚ÄìWhen training, be careful not to include raw or engi-\\nneered features that are computed from the classifica-\\ntion/regression label\\nData Pipelines\\n‚Ä¢Should be designed & built in advance for at-scale applica-\\ntions\\n‚Ä¢Batching vs. Streaming\\n‚ÄìBatching : Useofdatastoredindatalakes,processedin\\nperiodic intervals\\n‚ÄìStreaming (data streams) : Useofdatafromlivestreams.\\nUnique challenge due to 3ùëâùë†: Volume, Velocity (real-\\ntime), Variety (esp. unstructred data) (useful tool:\\nCloud Dataflow )\\n‚Ä¢Monitoring\\n‚Äì‚ÄùFourGoldenSignals‚Äùofyourcloud-basedservice: la-\\ntency, traffic, error, saturation\\n‚ÄìDashboards (Stackdriver Cloud Monitoring Dash-\\nboards API) can be a powerful tool in displaying mul-\\ntiple metrics\\n‚Ä¢Privacy,compliance,legalissues: Knowwhattherestrictions\\nareandplanahead(e.g. privacy-preservingML/AI,corrupt-\\ning input, ...)(useful tool: Cloud IAM )II. ML Model Development\\nModel Development At-a-Glance\\nGeneric ML Workflow\\n1.Training\\n‚Ä¢Choose a model framework\\n‚ÄìSupervised\\n‚ÄìUnsupervised\\n‚Ä¢Consider Transfer Learning (if applicable)\\n‚Ä¢Monitoring / tracking metrics')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcb8f95-cac2-4019-a27b-e41a6e8f6c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-vertexai\n",
    "\n",
    "# Instantiation\n",
    "# Now we can instantiate our model object and generate embeddings:\n",
    "\n",
    "# Check the list of Supported Models\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "# Initialize the a specific Embeddings Model version\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0db0c92-28a2-4290-a44b-a5ab56527054",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_chroma in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain_chroma) (0.4.24)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain_chroma) (0.115.0)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1.40 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain_chroma) (0.3.12)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain_chroma) (1.26.4)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.7.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.12.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.20.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.10.7)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.38.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain_chroma) (0.1.132)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain_chroma) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.35.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.9)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain_chroma) (0.27.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (74.1.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.28->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.28->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from starlette<0.39.0,>=0.37.2->fastapi<1,>=0.95.2->langchain_chroma) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.25.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (13.8.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (13.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi<1,>=0.95.2->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi<1,>=0.95.2->langchain_chroma) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain_chroma) (1.0.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2024.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.20.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659483f-5f4e-4f85-9bff-365764dfe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Debug chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8793de4c-4d8b-4965-a4ac-52b845b9638e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "\n",
    "# vector_store = Chroma(\n",
    "#     collection_name=\"example_collection\",\n",
    "#     embedding_function=embeddings,\n",
    "#     persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9698cd-5e44-4ab2-8ebc-f03aa56b2638",
   "metadata": {},
   "source": [
    "#### Debug duckduckgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e456d-a55f-4d8f-a52f-2b174b23f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# search = DuckDuckGoSearchRun()\n",
    "\n",
    "# search.invoke(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc045b6a-f6d0-4022-8c78-f0c8fb7a6d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 06:32:25,093 - 140433518380224 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mNews Seacher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mSearch for AI 2024 and create key points for each news.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mNews Seacher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to search for news about AI 2024 using the News DB Tool and extract key points for each article.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mNews DB Tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"AI 2024\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Failed to retrieve news.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mNews Seacher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The News DB Tool failed.  I'll try a broader search term to see if I can get any results.  If that fails, I'll have to report that I couldn't retrieve any news.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mNews DB Tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"Artificial Intelligence 2024\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Failed to retrieve news.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mNews Seacher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "I am unable to provide key points for AI 2024 news because the available tool, News DB Tool, failed to retrieve any relevant articles.  I attempted searches for both \"AI 2024\" and \"Artificial Intelligence 2024\" and both returned failures.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWriter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "    Go step by step.\n",
      "    Step 1: Identify all the topics received.\n",
      "    Step 2: Use the Get News Tool to verify the each topic by going through one by one.\n",
      "    Step 3: Use the Search tool to search for information on each topic one by one. \n",
      "    Step 4: Go through every topic and write an in-depth summary of the information retrieved.\n",
      "    Don't skip any topic.\n",
      "    \u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWriter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The task is to summarize key points of AI 2024 news.  I need to identify specific topics within AI 2024, verify them using the Get News Tool, research them with the duckduckgo_search tool, and summarize the findings. Since the prompt mentions the News DB tool failing, I'll try broader and more specific searches with the available tools.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mGet News Tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"Artificial Intelligence trends\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "[]\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import requests, os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "\n",
    "embedding_function = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "# Tool 1 : Save the news articles in a database\n",
    "class SearchNewsDB:\n",
    "    @tool(\"News DB Tool\")\n",
    "    def news(query: str):\n",
    "        \"\"\"Fetch news articles and process their contents.\"\"\"\n",
    "        API_KEY = os.getenv('65b726cdebac48f1ab5395c9802f6d48')  # Fetch API key from environment variable 65b726cdebac48f1ab5395c9802f6d48\n",
    "        base_url = \"https://newsapi.org/v2/everything\"\n",
    "        \n",
    "        params = {\n",
    "            'q': query,\n",
    "            'sortBy': 'publishedAt',\n",
    "            'apiKey': API_KEY,\n",
    "            'language': 'en',\n",
    "            'pageSize': 5,\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            return \"Failed to retrieve news.\"\n",
    "        \n",
    "        articles = response.json().get('articles', [])\n",
    "        all_splits = []\n",
    "        for article in articles:\n",
    "            # Assuming WebBaseLoader can handle a list of URLs\n",
    "            loader = WebBaseLoader(article['url'])\n",
    "            docs = loader.load()\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "            splits = text_splitter.split_documents(docs)\n",
    "            all_splits.extend(splits)  # Accumulate splits from all articles\n",
    "\n",
    "        # Index the accumulated content splits if there are any\n",
    "        if all_splits:\n",
    "            vectorstore = Chroma.from_documents(all_splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
    "            retriever = vectorstore.similarity_search(query)\n",
    "            return retriever\n",
    "        else:\n",
    "            return \"No content available for processing.\"\n",
    "\n",
    "# Tool 2 : Get the news articles from the database\n",
    "class GetNews:\n",
    "    @tool(\"Get News Tool\")\n",
    "    def news(query: str) -> str:\n",
    "        \"\"\"Search Chroma DB for relevant news information based on a query.\"\"\"\n",
    "        vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
    "        retriever = vectorstore.similarity_search(query)\n",
    "        return retriever\n",
    "\n",
    "# Tool 3 : Search for news articles on the web\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# 2. Creating Agents\n",
    "news_search_agent = Agent(\n",
    "    role='News Seacher',\n",
    "    goal='Generate key points for each news article from the latest news',\n",
    "    backstory='Expert in analysing and generating key points from news content for quick updates.',\n",
    "    tools=[SearchNewsDB().news],\n",
    "    allow_delegation=True,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "writer_agent = Agent(\n",
    "    role='Writer',\n",
    "    goal='Identify all the topics received. Use the Get News Tool to verify the each topic to search. Use the Search tool for detailed exploration of each topic. Summarise the retrieved information in depth for every topic.',\n",
    "    backstory='Expert in crafting engaging narratives from complex information.',\n",
    "    tools=[GetNews().news, search_tool],\n",
    "    allow_delegation=True,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# 3. Creating Tasks\n",
    "news_search_task = Task(\n",
    "    description='Search for AI 2024 and create key points for each news.',\n",
    "    agent=news_search_agent,\n",
    "    tools=[SearchNewsDB().news],\n",
    "    expected_output='A structured email accourding to the instructions'\n",
    ")\n",
    "\n",
    "writer_task = Task(\n",
    "    description=\"\"\"\n",
    "    Go step by step.\n",
    "    Step 1: Identify all the topics received.\n",
    "    Step 2: Use the Get News Tool to verify the each topic by going through one by one.\n",
    "    Step 3: Use the Search tool to search for information on each topic one by one. \n",
    "    Step 4: Go through every topic and write an in-depth summary of the information retrieved.\n",
    "    Don't skip any topic.\n",
    "    \"\"\",\n",
    "    agent=writer_agent,\n",
    "    context=[news_search_task],\n",
    "    tools=[GetNews().news, search_tool],\n",
    "    expected_output='A structured email accourding to the instructions'\n",
    ")\n",
    "\n",
    "# 4. Creating Crew\n",
    "news_crew = Crew(\n",
    "    agents=[news_search_agent, writer_agent],\n",
    "    tasks=[news_search_task, writer_task],\n",
    "    process=Process.sequential, \n",
    "    manager_llm=llm,\n",
    "    expected_output='A structured email accourding to the instructions'\n",
    ")\n",
    "\n",
    "# Execute the crew to see RAG in action\n",
    "result = news_crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be26be-b13d-4a72-b9e9-e2d1cdf023b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa71351-faad-445e-bfaf-0408a039550d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

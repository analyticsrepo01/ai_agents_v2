{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vf3Z06zIJLq-",
    "outputId": "c739ca5e-d2da-4082-db2f-cf8bd6b3d3b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain langchain_core langchain_community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "d3_a6WEmKPQ7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://my-project-0004-346516-pytorch112kagglewbi-us-central1/...\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.storage.buckets.create) HTTPError 409: Your previous request to create the named bucket succeeded and you already own it.\n",
      "mkdir: cannot create directory ‘output’: File exists\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "UNIQUE_PREFIX = socket.gethostname()\n",
    "UNIQUE_PREFIX = re.sub('[^A-Za-z0-9]+', '', UNIQUE_PREFIX)\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-{UNIQUE_PREFIX}-{LOCATION}\"\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"  # @param {type:\"string\"}\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud storage buckets create {BUCKET_URI} --project={PROJECT_ID} --location={LOCATION}\n",
    "! mkdir output\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "# from langchain_vertexai import ChatGemini\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import uuid, os\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name='gemini-1.5-pro-001', #\"gemini-1.0-pro-002\", # Replace with your desired Gemini model\n",
    "    # model_name='gemini-1.5-flash', #\"gemini-1.0-pro-002\", # Replace with your desired Gemini model\n",
    "    project_id=os.getenv(PROJECT_ID), # Your Vertex AI project ID\n",
    "    location=\"us-central1\", # Your Vertex AI location\n",
    "    stream=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "DlY2SFYgKXAB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "3_GsyYVGKv_X"
   },
   "outputs": [],
   "source": [
    "model = llm #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ySqctD_vK4Tp"
   },
   "outputs": [],
   "source": [
    "# Define the prompts\n",
    "step1_prompt = \"\"\"Step 1: I have a problem related to {input}.\n",
    "Could you brainstorm three distinct solutions?\n",
    "Please consider a variety of factors such as {perfect_factors}\"\"\"\n",
    "\n",
    "step2_prompt = \"\"\"Step 2: For each of the three proposed solutions, evaluate their potential.\n",
    "Consider their pros and cons, initial effort needed, implementation difficulty, potential challenges,\n",
    "and the expected outcomes. Assign a probability of success and a confidence level\n",
    "to each option based on these factors.\n",
    "\n",
    "Solutions:\n",
    "{solutions}\"\"\"\n",
    "\n",
    "step3_prompt = \"\"\"Step 3: For each solution, deepen the thought process.\n",
    "Generate potential scenarios, strategies for implementation, any necessary partnerships or resources,\n",
    "and how potential obstacles might be overcome. Also, consider any potential unexpected outcomes\n",
    "and how they might be handled.\n",
    "\n",
    "Evaluation:\n",
    "{review}\"\"\"\n",
    "\n",
    "step4_prompt = \"\"\"Step 4: Based on the evaluations and scenarios,\n",
    "rank the solutions in order of promise. Provide a justification for each ranking\n",
    "and offer any final thoughts or considerations for each solution.\n",
    "\n",
    "Detailed analysis:\n",
    "{deepen_thought_process}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "kODpkdOWLMXQ"
   },
   "outputs": [],
   "source": [
    "# Define the output structures\n",
    "class Solutions(BaseModel):\n",
    "    solutions: list[str]\n",
    "\n",
    "class Review(BaseModel):\n",
    "    review: str\n",
    "\n",
    "class DeepThought(BaseModel):\n",
    "    deep_thought: str\n",
    "\n",
    "class RankedSolutions(BaseModel):\n",
    "    ranked_solutions: str\n",
    "\n",
    "# Define the overall state\n",
    "class OverallState(TypedDict):\n",
    "    input: str\n",
    "    perfect_factors: str\n",
    "    solutions: Annotated[list[str], operator.add]\n",
    "    reviews: Annotated[list[str], operator.add]\n",
    "    deep_thoughts: Annotated[list[str], operator.add]\n",
    "    ranked_solutions: str\n",
    "\n",
    "# Define the state for individual solution processing\n",
    "class SolutionState(TypedDict):\n",
    "    solution: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "JUbEPQunLSA1"
   },
   "outputs": [],
   "source": [
    "# Graph components\n",
    "def generate_solutions(state: OverallState):\n",
    "    prompt = step1_prompt.format(input=state[\"input\"], perfect_factors=state[\"perfect_factors\"])\n",
    "    response = model.with_structured_output(Solutions).invoke(prompt)\n",
    "    return {\"solutions\": response.solutions}\n",
    "\n",
    "def evaluate_solution(state: SolutionState):\n",
    "    prompt = step2_prompt.format(solutions=state[\"solution\"])\n",
    "    response = model.with_structured_output(Review).invoke(prompt)\n",
    "    return {\"reviews\": [response.review]}\n",
    "\n",
    "def deepen_thought(state: SolutionState):\n",
    "    prompt = step3_prompt.format(review=state[\"solution\"])\n",
    "    response = model.with_structured_output(DeepThought).invoke(prompt)\n",
    "    return {\"deep_thoughts\": [response.deep_thought]}\n",
    "\n",
    "def rank_solutions(state: OverallState):\n",
    "    deep_thoughts = \"\\n\\n\".join(state[\"deep_thoughts\"])\n",
    "    prompt = step4_prompt.format(deepen_thought_process=deep_thoughts)\n",
    "    response = model.with_structured_output(RankedSolutions).invoke(prompt)\n",
    "    return {\"ranked_solutions\": response.ranked_solutions}\n",
    "\n",
    "# Define the mapping logic\n",
    "def continue_to_evaluation(state: OverallState):\n",
    "    return [Send(\"evaluate_solution\", {\"solution\": s}) for s in state[\"solutions\"]]\n",
    "\n",
    "def continue_to_deep_thought(state: OverallState):\n",
    "    return [Send(\"deepen_thought\", {\"solution\": r}) for r in state[\"reviews\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "lljoVKA2LVsq"
   },
   "outputs": [],
   "source": [
    "# Construct the graph\n",
    "graph = StateGraph(OverallState)\n",
    "\n",
    "graph.add_node(\"generate_solutions\", generate_solutions)\n",
    "graph.add_node(\"evaluate_solution\", evaluate_solution)\n",
    "graph.add_node(\"deepen_thought\", deepen_thought)\n",
    "graph.add_node(\"rank_solutions\", rank_solutions)\n",
    "\n",
    "graph.add_edge(START, \"generate_solutions\")\n",
    "graph.add_conditional_edges(\"generate_solutions\", continue_to_evaluation, [\"evaluate_solution\"])\n",
    "graph.add_conditional_edges(\"evaluate_solution\", continue_to_deep_thought, [\"deepen_thought\"])\n",
    "graph.add_edge(\"deepen_thought\", \"rank_solutions\")\n",
    "graph.add_edge(\"rank_solutions\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "fCjMG4jyLofG"
   },
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Wb7_nrXLrEV",
    "outputId": "69338cd3-add8-459a-abe2-0c0764fef3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_solutions': {'solutions': ['1. **Implement a community health worker program:** Train and employ local residents to provide basic healthcare services and education in their communities. This is a cost-effective way to increase healthcare access, especially in remote areas, and can empower individuals to take charge of their health.\\\\n2. **Leverage mobile technology:** Develop mobile health (mHealth) applications for disease surveillance, appointment scheduling, and telehealth consultations. This can improve efficiency, reduce travel costs, and overcome geographical barriers.\\\\n3. **Invest in sustainable infrastructure:** Build energy-efficient healthcare facilities powered by renewable energy sources. This reduces the environmental impact of healthcare delivery and ensures long-term sustainability.']}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimproving health care in a developing city\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mperfect_factors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcost, efficiency, environmental impact, and user experience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/__init__.py:963\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1489\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langchain_core/runnables/base.py:2368\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2368\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/graph/graph.py:70\u001b[0m, in \u001b[0;36mBranch._route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reader:\n\u001b[0;32m---> 70\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# passthrough additional keys from node to branch\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# only doable when using dict states\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/read.py:94\u001b[0m, in \u001b[0;36mChannelRead.do_read\u001b[0;34m(config, channel, fresh, mapper)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mapper:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapper(\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfresh\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1537\u001b[0m, in \u001b[0;36m_local_read\u001b[0;34m(checkpoint, channels, writes, select, fresh)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ChannelsManager(channels, checkpoint) \u001b[38;5;28;01mas\u001b[39;00m channels:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[43m_apply_writes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_channels(channels, select)\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1572\u001b[0m, in \u001b[0;36m_apply_writes\u001b[0;34m(checkpoint, channels, pending_writes)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;66;03m# Group writes by channel\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chan, val \u001b[38;5;129;01min\u001b[39;00m pending_writes:\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;241m==\u001b[39m TASKS:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(s)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:  \u001b[38;5;66;03m# Replace 'ExceptionType' with the specific exception you want to catch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Code to handle the exception\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43me\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "# Call the graph\n",
    "try:\n",
    "    for s in app.stream({\n",
    "        \"input\": \"improving health care in a developing city\",\n",
    "        \"perfect_factors\": \"cost, efficiency, environmental impact, and user experience\"\n",
    "    }):\n",
    "        print(s)\n",
    "finally:  # Replace 'ExceptionType' with the specific exception you want to catch\n",
    "    # Code to handle the exception\n",
    "    print(f\"An error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rro5afKQMQdX"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oJy6XJyMSAo",
    "outputId": "95d73434-1427-431b-8227-5adc1ab4e418"
   },
   "outputs": [],
   "source": [
    "pprint(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "TCiWVGEULzWG",
    "outputId": "78725846-3a4d-4c4f-bbd3-c9d188e001ef"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0d6qKGSMBcD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py312",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "py312 (Local)",
   "language": "python",
   "name": "conda-root-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

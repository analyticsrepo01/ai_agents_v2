{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b236e1-5c65-4050-905c-0c6d16c71a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "llm = ChatVertexAI(model_name= 'gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518464b-7c76-44f0-b342-544983b376ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily-python in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from tavily-python) (2.32.3)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from tavily-python) (0.7.0)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from tavily-python) (0.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken>=0.5.1->tavily-python) (2024.9.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->tavily-python) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->tavily-python) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->tavily-python) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->tavily-python) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->tavily-python) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install langgraph\n",
    "# %pip install langgraph-checkpoint-sqlite\n",
    "%pip install tavily-python\n",
    "%pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "with open('env2.txt', 'r') as file:\n",
    "    serper_api_key = file.read().strip()\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"] = serper_api_key\n",
    "\n",
    "tavily = TavilyClient(api_key=serper_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# for s in graph.stream({\n",
    "#     'task': \"what is the difference between langchain and langsmith\",\n",
    "#     \"max_revisions\": 2,\n",
    "#     \"revision_number\": 1,\n",
    "# }, thread, ):\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0d4b2-3e40-4f75-835c-2df0b9264602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1664b5-75e0-46b7-9c2b-4ac9171f4597",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ae270-3ec3-484a-b729-df7d2b7b0f76",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebfa79-c7fc-4aaa-b668-64e5b6cede80",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.graph)\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8543a16c-f8f7-446c-9774-0ee364bf50cb",
   "metadata": {
    "height": 30
   },
   "source": [
    "# Main new test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e993b-ddd6-4ec7-9125-30cae1d86fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# setup the simple tools using LangChain tool decorator\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def square(a: int) -> int:\n",
    "    \"\"\"Calculates the square of a number.\"\"\"\n",
    "    a = int(a)\n",
    "    return a * a\n",
    "\n",
    "# setup the toolkit\n",
    "toolkit = [add, multiply, square]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74820d8b-940e-4806-8e5e-5def5e3398b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "#define system prompt for tool calling agent\n",
    "system_prompt = \"\"\" You are a mathematical assistant.\n",
    "        Use your tools to answer questions. If you do not have a tool to\n",
    "        answer the question, say so. \"\"\"\n",
    "\n",
    "tool_calling_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tool_runnable = create_tool_calling_agent(llm, toolkit, prompt  = tool_calling_prompt)\n",
    "tool_actions = tool_runnable.invoke({\"input\": \"hi! what's 1+1 and  2 times 2\", 'intermediate_steps': []})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f13320-3865-4b5a-b864-f9254d31336a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_tool_agent(state):\n",
    "    agent_outcome = tool_runnable.invoke(state)\n",
    "\n",
    "    #this agent will overwrite the agent outcome state variable\n",
    "    return {\"agent_outcome\": agent_outcome}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b30a0-4f34-4d8f-8608-54f0122d7339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "# tool executor invokes the tool action specified from the agent runnable\n",
    "# they will become the nodes that will be called when the agent decides on a tool action.\n",
    "\n",
    "tool_executor = ToolExecutor(toolkit)\n",
    "\n",
    "# Define the function to execute tools\n",
    "# This node will run a different tool as specified in the state variable agent_outcome\n",
    "def execute_tools(state):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = state['agent_outcome']\n",
    "    if type(agent_action) is not list:\n",
    "        agent_action = [agent_action]\n",
    "    steps = []\n",
    "    #sca only returns an action while tool calling returns a list\n",
    "    # convert single actions to a list\n",
    "    \n",
    "    for action in agent_action:\n",
    "    # Execute the tool\n",
    "        output = tool_executor.invoke(action)\n",
    "        print(f\"The agent action is {action}\")\n",
    "        print(f\"The tool result is: {output}\")\n",
    "        steps.append((action, str(output)))\n",
    "    # Return the output\n",
    "    return {\"intermediate_steps\": steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49275e3a-f769-49fc-863c-222931f970a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated,Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain.agents.output_parsers.tools import ToolAgentAction\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "   # The input string from human\n",
    "   input: str\n",
    "   # The list of previous messages in the conversation\n",
    "   chat_history: list[BaseMessage]\n",
    "   # The outcome of a given call to the agent\n",
    "   # Needs 'list' as a valid type as the tool agent returns a list.\n",
    "   # Needs `None` as a valid type, since this is what this will start as\n",
    "   # this state will be overwritten with the latest everytime the agent is run\n",
    "   agent_outcome: Union[AgentAction, list, ToolAgentAction, AgentFinish, None]\n",
    "\n",
    "   # List of actions and corresponding observations\n",
    "   # These actions should be added onto the existing so we use `operator.add` \n",
    "   # to append to the list of past intermediate steps\n",
    "   intermediate_steps: Annotated[list[Union[tuple[AgentAction, str], tuple[ToolAgentAction, str]]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1d7ba-3e0e-47b5-8f24-3fe2c3c6f153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_continue(data):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(data['agent_outcome'], AgentFinish):\n",
    "        return \"END\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"CONTINUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbe55e-03bd-453d-bd1f-2a1637430b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# When nodes are called, the functions for to the tools will be called. \n",
    "workflow.add_node(\"agent\", run_tool_agent)\n",
    "\n",
    "\n",
    "# Add tool invocation node to the graph\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Define which node the graph will invoke at start.\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add flow logic with static edge.\n",
    "# Each time a tool is invoked and completed we want to \n",
    "# return the result to the agent to assess if task is complete or to take further actions \n",
    "\n",
    "#each action invocation has an edge leading to the agent node.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "\n",
    "# Add flow logic with conditional edge.\n",
    "workflow.add_conditional_edges(\n",
    "    # first parameter is the starting node for the edge\n",
    "    \"agent\",\n",
    "    # the second parameter specifies the logic function to be run\n",
    "    # to determine which node the edge will point to given the state.\n",
    "    should_continue,\n",
    "\n",
    "    #third parameter defines the mapping between the logic function \n",
    "    #output and the nodes on the graph\n",
    "    # For each possible output of the logic function there must be a valid node.\n",
    "    {\n",
    "        # If 'continue' we proceed to the action node.\n",
    "        \"CONTINUE\": \"action\",\n",
    "        # Otherwise we end invocations with the END node.\n",
    "        \"END\": END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ef79b-f5fe-4965-8e0f-ebb3a9b786d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Finally, compile the graph! \n",
    "# This compiles it into a LangChain Runnable,\n",
    "app = workflow.compile(checkpointer = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39290d9d-4a57-4957-95ad-6a399d7d5d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\"input\": \"give me 1+1 and then 2 times 2\", \"chat_history\": []} \n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for s in app.stream(inputs, config = config):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd924f-ad81-4523-b3b0-e9429a373d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py312",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "py312 (Local)",
   "language": "python",
   "name": "conda-base-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
